<!--
	作者：Sariay
	时间：2018-08-26
	描述：There may be a bug, but don't worry, Qiling(器灵) says that it can work normally! aha!
-->
<!DOCTYPE html>
<html class="html-loading">
		

<head>
	<meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">
  <title>
    
       | Xue&#39;s Blog
    
  </title>
  <meta name="author" content="薛晓萱">
  <meta name="keywords" content="NLP、算法、知识图谱" />
  <meta name="description" content="一个不成熟的理想主义者" />
	<!-- favicon -->
  <link rel="shortcut icon" href="/img/favicon.png">

  <!-- css -->
  
<link rel="stylesheet" href="/css/Annie.css">

  
  <!-- jquery -->
	
<script src="/plugin/jquery/jquery.min.js"></script>


<script>
    const CONFIG_BGIMAGE = {
      mode: 'normal',
      normalSrc: '/img/5.jpg',
      randomYouMax: 110,
      randomYouSrc: 'https://sariay.github.io/Random-img/',
	  randomOtherSrc: 'https://api.berryapi.net/?service=App.Bing.Images&day=-0',
	  preloaderEnable: true
    }
	
    const CONFIG_LEACLOUD_COUNT = {
      enable: false,
	  appId: 'AU8...',
	  appKey: '4cU...',
	  serverURLs: 'http' || ' '
    }
  </script>
<meta name="generator" content="Hexo 5.2.0"></head>
	<body>
		<!-- Preloader -->

	<div id="preloader">
		<div class="pre-container">
			
				<div class="spinner">
					<div class="double-bounce1"></div>
					<div class="double-bounce2"></div>
				</div>
						
		</div>
	</div>


<!-- header -->
<header class="fixbackground bg-pan-br">
	<div class="mask">
		<!-- motto -->
		<div class="h-body">	
			
				<div class="motto text-shadow-pop-left">
					<p class="content" id="motto-content">获取中...</p>
					<p>-<p>
					<p class="author" id="motto-author">Just a minute...</p>
				</div>
			
		</div>
		
		<!-- others: such as time... -->			
		<div class="h-footer">
			<a href="javascript:;" id="read-more" class="scroll-down">
				<span class="icon-anchor1 animation-scroll-down"></span>
			</a>
		</div>
	</div>
</header>

<div id="navigation-hide">
	<!-- Progress bar -->
	<div id="progress-bar"></div>

	<!-- Progress percent -->
	<div id="progress-percentage"><span>0.0%</span></div>

	<div class="toc-switch"><span class="switch-button">目录</span></div>

	<!-- Page title -->
	<p>
		
			「」
		
	</p>

	
	

	<!-- Nav trigger for navigation-H-->
	<a class="nav-trigger"><span></span></a>
</div>

<!-- Navigation in div(id="navigation-H") -->
<nav class="nav-container" id="cd-nav">
	<div class="nav-header">
		<span class="logo"> 
			<img src="/img/logo.png">
		</span>
		<a href="javascript:;" class="nav-close"></a>
	</div>
	
	<div class="nav-body">
		<ul id="global-nav">
	
		<li class="menu-home">
			<a href="/" class="menu-item-home" target="_blank">主页</a>
		</li>
		
	
		<li class="menu-archive">
			<a href="/archives" class="menu-item-archive" target="_blank">归档</a>
		</li>
		
	
		<li class="menu-categories">
			<a href="/categories" class="menu-item-categories" target="_blank">分类</a>
		</li>
		
	
		<li class="menu-tags">
			<a href="/tags" class="menu-item-tags" target="_blank">标签</a>
		</li>
		
	
		<li class="menu-about">
			<a href="/about" class="menu-item-about" target="_blank">关于</a>
		</li>
		
	

	
</ul>
	</div>
	
	<div class="nav-footer">
		<ul id="global-social">
	
		<li>
			<a href="http://github.com/" target="_blank">
				<span class="icon-one"><span class="path1"></span><span class="path2"></span></span>
			</a>
		</li>
	
		<li>
			<a href="http://github.com/" target="_blank">
				<span class="icon-zhihu"></span>
			</a>
		</li>
	
		<li>
			<a href="http://github.com/" target="_blank">
				<span class="icon-github"></span>
			</a>
		</li>
	
		<li>
			<a href="http://github.com/" target="_blank">
				<span class="icon-sina-weibo "></span>
			</a>
		</li>
	
		<li>
			<a href="http://github.com/" target="_blank">
				<span class="icon-pinterest2"></span>
			</a>
		</li>
	
		<li>
			<a href="http://github.com/" target="_blank">
				<span class="icon-instagram"></span>
			</a>
		</li>
	
		<li>
			<a href="http://github.com/" target="_blank">
				<span class="icon-twitter"></span>
			</a>
		</li>
	
		<li>
			<a href="/atom.xml" target="_blank">
				<span class="icon-rss"></span>
			</a>
		</li>
			
</ul>

	</div>
</nav>
			
		<!--main-->
		<main>
			<!--
	时间：2018-11-17
	描述：
		插件名称：katelog.min.js
		插件作者：KELEN
		插件来源: https://github.com/KELEN/katelog
-->

	
		<div class="layout-toc">
			<div id="layout-toc">
				<div class="k-catelog-list" id="catelog-list" data-title="文章目录"></div>
			</div>
		</div>

		
<script src="/plugin/toc/katelog.min.js"></script>


		
	 

<div class="layout-post">
	<div id="layout-post">
		<div class="article-title">
			
		</div>

		<div class="article-meta">
			<span>
				<i class="icon-calendar1"></i>
				
				




	更新于

	<a href="/2020/09/15/Privacy%20Risks%20of%20General-Purpose%20Language%20Models/" itemprop="url">
		<time datetime="2020-09-15T04:20:35.091Z" itemprop="dateUpdated">
	  		2020-09-19
	  </time>
	</a> 



			</span>
			<span>
						
			</span>
			
			



		</div>

		<div class="article-content" id="article-content">
			<h2 id="通用语言模型的隐私风险（翻译）"><a href="#通用语言模型的隐私风险（翻译）" class="headerlink" title="通用语言模型的隐私风险（翻译）"></a>通用语言模型的隐私风险（翻译）</h2><h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h4><p>最近，在自然语言处理(NLP)中为文本特征提取构建通用语言模型的新范例(例如Google的BERT和OpenAI的GPT-2)已经出现，这是自然语言处理系统中将文本转换为向量(即嵌入)以进行下游建模的标准过程，并开始在各种下游NLP任务和现实世界系统(例如Google的搜索引擎[6])中找到应用。 为了获得通用的文本嵌入，这些语言模型具有高度复杂的结构，具有数百万个可学习参数，并且在使用之前通常要对数十亿个句子进行预训练。 正如广泛认识的那样，这样的实践确实提高了许多下游NLP任务的最先进性能。</p>
<p>但是，改进后的实用程序不是免费的。 我们发现，通用语言模型中的文本嵌入会从纯文本中捕获很多敏感信息。 一旦被对手访问，可以对嵌入进行反向工程，以披露受害者的敏感信息，以进一步骚扰。 尽管这样的隐私风险可能会对这些有前途的NLP工具的未来使用构成一定的威胁，但到目前为止，主流行业级语言模型都没有公开的攻击或系统的评估。</p>
<p>为了弥合这种差距，我们通过四个案例研究，对8种最新语言模型的隐私风险进行了首次系统研究。 通过构建2种新颖的攻击类别，我们的研究表明上述隐私风险确实存在，并且可能对通用语言模型在身份，基因组，医疗保健和位置等敏感数据上的应用构成实际威胁。 例如，当从病人的医学描述的Bert嵌入中推断出精确的疾病部位时，我们显示出该对手几乎没有先验知识可以达到约75％的准确度。 作为可能的对策，我们提出了四种不同的防御措施（通过舍入，差分隐私，对抗训练和子空间投影）来模糊化未保护的嵌入物，以达到缓解目的。 通过广泛的评估，我们还对每种防御措施带来的效用-隐私权衡进行了初步分析，我们希望这可以促进未来的缓解研究。</p>
<h4 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h4><p>随着自然语言处理（NLP）中深度学习技术的进步，去年见证了Google，OpenAI和Facebook等行业领导者在构建通用语言模型方面的许多突破[16]，[17]，[41]，[44]， [54]，[55]，[67]，[76]，已广泛用于各种下游NLP任务，例如文本分类和问答[15]，并开始在现实系统中找到其应用，例如Google的搜索引擎[6] ]，据称是“过去五年中最大的飞跃，也是搜索历史上最大的飞跃之一” [6]。</p>
<p>不同于传统的统计模型和浅层神经网络模型，通用语言模型通常包括基于Google的Bert和OpenAI的GPT-2在内的基于Transformer的预训练的巨型语言模型，这些模型由Transformer块[72]层组成，具有数百万个可学习的参数，通常在发布前经过数十亿的句子预训练。根据官方指南[2]，用户可以将这些经过预训练的模型用作文本特征提取器，以将句子编码为密集向量或称为句子嵌入，可以进一步用于各种下游任务（例如，文本分类）。随着Bert的发布，Google AI展望了通用语言模型的未来，因为“世界上任何人都可以在一个cloud上大约30分钟内训练自己的最先进的问答系统（或其他各种模型） TPU，或在几个小时内使用单个GPU” [4]。</p>
<p>尽管有很强的前瞻性，但我们还是第一次观察到这些通用语言模型倾向于在句子嵌入中捕获很多敏感信息，这为对手留下了侵犯隐私的窗口。例如，在智能医疗中这些语言模型的典型用例中，第三方组织与医院合作开发患者指南系统，该系统会根据症状描述自动将患者分配到适当的科室。由于Google’sBert [17]的普遍性，该组织仅需请求医院提供患者症状描述的嵌入内容，以作为构建高效系统的基本信息。由于缺乏对隐私保护特性的了解 在通用语言模型中，医院可能期望共享矢量形式的功能比共享纯文本的私密性要小得多，尤其是当它们被告知时，编码规则本身是基于高度复杂的神经网络，该网络接近黑匣子。实际上，我们通过附录F中的实验观察到，即使使用NLP中的标准解码器模块，也很难从嵌入中恢复任何有用的信息。 但是，在包括Bert和GPT-2在内的八种最先进的语言模型中，<u>我们设计了一个轻量级但有效的攻击管道，在不受保护的句子嵌入情况下，即使具有几乎为零领域知识的对手也可以在未知的纯文本中高精度地推断出与领域相关的敏感信息。</u>在上面的医疗示例中，我们的观察强烈表明，诚实但好奇的服务提供者作为对手可以轻松推断出特定受害者的身份，性别，出生日期，疾病类型甚至确切的疾病地点，前提是目标信息 出现在他/她的原始描述中。</p>
<p><strong>我们的工作</strong>    在本文中，我们对通用语言模型的潜在隐私风险进行了首次系统研究。 具体来说，我们想回答主要的研究问题：<u>当对手只能访问他/她提交的嵌入内容时，对手是否有可能在未知的纯文本中推断用户的私人信息？</u>如果答案是肯定的，那么最新的NLP工具在诸如协作学习或联合学习[36]，[37]，[46]等令人信服的学习范式中的未来应用可能会受到很大的威胁和限制，尤其是在对隐私至关重要的领域，包括医疗保健，基因组学和金融。 除了我们主要研究对象的新颖性之外，与大多数现有工作相比，我们的研究问题也有其特殊性，包括成员推断攻击[63]，属性推断攻击[23]和模型反演攻击[21]，信息来源和攻击目标。 我们的研究与相关攻击之间的更详细比较可以在第二部分中找到。</p>
<p>尽管计算机视觉领域的先前工作表明可以通过自动编码器[18]或生成模型[61]从其预先训练的嵌入中重建原始图像的可能性，但之前在NLP中没有类似的攻击报道。从我们的角度来看，tokens的离散性和词汇的不可见性是阻止对文本嵌入进行重构攻击成功的两个主要技术挑战。 一方面，tokens的离散性使得在所有可能的句子空间上的搜索效率极低，这主要是因为学习目标不再像视觉情况那样可区分，因此基于梯度的方法几乎无法工作[79]。另一方面，语言模型作为黑匣子被访问，对手不了解真实的词汇，否则对手就无法将恢复的单词索引序列转换为纯文本[38]。 即使对手准备了自己的词汇表，它可能太小而无法在未知的纯文本中包含一些敏感词，也可能太大而带来很高的计算复杂性。</p>
<p>为了解决上述挑战，我们建议通过推理从文本嵌入中重建敏感信息。从以下观察中得到启发：文本中与隐私相关的信息通常出现在小段中，或者与某些关键字的出现有关[62]，我们构造了两种不同的攻击类别，即模式重构攻击和关键字推理攻击，以展示敏感信息如何 可以从文本嵌入中提取。在模式重建攻击中，原始文本具有固定的模式（例如基因组序列），而对手试图恢复包含敏感信息（例如与疾病相关的基因表达）的原始序列的特定片段。在关键字推理攻击中，对手想要探查未知的纯文本（例如医学描述）是否包含某些敏感关键字（例如疾病部位）。 专注于一小部分，对手仅需要从有限数量的可能性中推断出重构目的，从而减轻了由tokens离散性引起的优化困难。同时，对手无需了解整个词汇表，如果对手只关心他/她感兴趣的单词。</p>
<p>在8种最先进的通用语言模型和4个（身份、基因组、医学、位置相关）案例研究中进行的大量实验表明，对手可以从其泄漏的嵌入中准确推断出目标用户的各种敏感信息。对于模式重建，当从20个长度的基因组序列的GPT-2嵌入中的任何指定位置推断出确切的核苷酸类型时，我们的攻击可分别达到98.2％和62.4％的最佳和平均准确度，而无需任何辅助信息 。对于关键词推理，我们的攻击在有无影子语料库的医学描述的BERT嵌入中推断出10个与身体相关的关键词时，平均正确率分别达到99.8%和74.8%。<u>这些结果有力地证明了上述隐私风险确实存在，并可能对敏感数据的通用语言模型的应用造成真正的威胁。</u>值得注意的是，我们所有的攻击仅需要将语言模型作为云服务（即ML as a service）访问，并且可以使用一台PC设备进行。 通过额外的消融研究，我们进一步讨论了一些与体系结构和数据相关的因素，这些因素可能会影响语言模型的隐私风险级别。此外，我们还通过量化，差分隐私[20]，对抗训练[57]和子空间投影[14]提出并评估了针对威胁的四种可能的对策。 我们希望我们的初步缓解研究能够为将来的国防研究提供启发，并为安全通用语言模型的设计做出贡献。</p>
<p>总而言之，我们做出以下贡献：</p>
<ul>
<li>我们发现了通用语言模型中潜在的隐私风险，结果表明，几乎为零的对手可以访问文本嵌入，从而可以泄露未知文本中的敏感信息。</li>
<li>我们设计了一条通用的攻击管道来利用文本嵌入中的用户隐私，并使用先进的深度学习技术实施两次实际攻击，以证明存在隐私风险。</li>
<li>我们将对8种最先进的通用语言模型进行首次系统评估，其中包括4种不同的案例研究，以证明隐藏的隐私风险，并对影响隐私的因素进行深入分析。</li>
<li>我们还提供了对四种可能的对策及其效用与隐私权衡的初步研究，我们希望这些对策可以促进未来的防御研究。</li>
</ul>
<h4 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a>2 相关工作</h4><p><strong>针对ML的隐私攻击</strong>。模型反转攻击最早是由Fredrikson等人提出的。 统计模型[22]以及后来推广到深度学习系统的信息[21]。 就攻击目标而言，Fredrikson等人对图像分类器的攻击表示要恢复代表特定类别的原型图像，而我们的攻击则旨在部分或全部恢复嵌入背后的纯文本。在信息来源方面，模型反转攻击主要依赖于模型本身的参数，而对于我们的攻击，信息源是从通用语言模型产生的句子嵌入。</p>
<p>同时，Fredrikson等。 [21]，[22]还讨论了模型反转攻击，即这种攻击会将来自模型输出的有关输入的敏感信息反转。据我们所知，他们最初的攻击主要是针对决策树模型实施的，并不直接适用于深度学习模型。后来，一些最近的工作提出了更细粒度的攻击，试图在训练阶段从未知的小批量中从预测[58]，[77]或梯度[47]，[82]中恢复精确的训练图像或文本。但是，其中两个针对从梯度中恢复文本的目标[47]，[82]利用了词袋中单词构成的显式表示，无法应用于我们的对抗环境中，该对抗环境从通用语言模型的密集句子嵌入中重建文本 。</p>
<p>作为模型反演攻击的补充，Shokri等人设计了针对机器学习模型的第一次成员推理攻击[63]，在过去几年中引起了广泛的研究兴趣[50]，[59]，[66]，[78]。 就攻击目标而言，成员推断试图揭示样本与真实私人训练集之间的联系。 就信息源而言，隶属推理攻击依赖于与输入样本关联的概率向量。 与隶属推断不同，另一项称为属性推断的工作旨在推断训练集是否具有一定的全局属性，这首先由[10]在浅层模型上进行研究，然后由[23]扩展至深层模型。</p>
<p><strong>使用ML进行隐私攻击。</strong>此外，之前还有很多使用ML方法评估用户隐私风险的工作，例如，他/她的生物医学和地质概况。例如，关于生物医学隐私，Humbert等人[30]，[31]利用图形模型从父母的关系和专家知识中推断出个人的基因组，近来[12]将其扩展到其他类型的生物医学数据。关于位置隐私，例如，Shokri等。 [64]使用马尔可夫链模型从模糊的位置信息中重建用户的实际踪迹，而一些最新的工作则利用聚类[8]或随机森林[80]从社交媒体（如哈希标签）中利用辅助渠道进行位置推断。</p>
<h4 id="3-准备工作"><a href="#3-准备工作" class="headerlink" title="3  准备工作"></a><strong>3  准备工作</strong></h4><h6 id="A-句子嵌入"><a href="#A-句子嵌入" class="headerlink" title="A.  句子嵌入"></a>A.  句子嵌入</h6><p>给定一个由<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600153801781.png" alt="1600153801781" style="zoom:50%;" />tokens组成的词汇表<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600153783153.png" alt="1600153783153" style="zoom:50%;" />，我们称一个序列<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600153828471.png" alt="1600153828471" style="zoom:50%;" />是长度为n的句子，如果该句子中每一个token或者词<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600153847838.png" alt="1600153847838" style="zoom:50%;" />都在词汇表<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600153890473.png" alt="1600153890473" style="zoom:50%;" />中。遵循表征学习的术语[11]，我们把从句子到实向量空间<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600154094748.png" alt="1600154094748" style="zoom:50%;" />的映射<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600154076791.png" alt="1600154076791" style="zoom:50%;" />称为特征抽取器。对于句子x，向量<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600154110388.png" alt="1600154110388" style="zoom:50%;" />被称为它的嵌入。</p>
<p>在提出通用语言模型之前，对词嵌入和句子嵌入作为两个传统的NLP任务进行了广泛的研究，为此存在几种成熟的算法。对于单词嵌入，像word2vec [49]这样的算法将单词编码为其向量表示形式，可以显着保留单词之间的相对语义，例如，发现queen和woman单词的嵌入差异几乎与king和man [49]相同。对于句子嵌入，像TF-IDF [60]这样的基于词频的算法直接对一个句子的词统计进行计数，因此产生的句子嵌入在词构成上是显式的，不适用于要求严格保密的场景[46]。其他基于学习的句子嵌入方法，如edoc2vec[42]借鉴了word2vec的思想，将句子编码成向量，在训练语料库中保持句子与其合成词之间的相关语义。因此，doc2vec生成的句子嵌入通常是语料库特有的，主要用于给定语料库的句子聚类或释义检测[40]，[42]。</p>
<p>近年来，通用语言模型的蓬勃发展极大地改变了我们在以下方面对嵌入的理解和使用方式。 一方面，由于上下文语词嵌入[52]是这些通用语言模型背后的基本概念，因此单词语嵌入和句子嵌入之间的界限不再清晰。直观地，上下文化单词嵌入表明同一单词的嵌入可以根据其出现的句子而变化。例如，在“我喜欢苹果”和“我喜欢苹果的电脑”中，单词苹果的上下文嵌入应该是不同的。因此，大多数通用语言模型将句子嵌入列为一种主要用例，而不是单词嵌入[2]，[74]。 另一方面，预训练的通用语言模型的句子嵌入具有更好的通用性，可以直接用作输入来训练下游学习模型，例如，通过简单的线性输出层，预训练的Bert模型的嵌入可以达到状态 11个NLP任务的艺术表现[17]。</p>
<h6 id="B-句子嵌入的通用语言模型"><a href="#B-句子嵌入的通用语言模型" class="headerlink" title="B.  句子嵌入的通用语言模型"></a>B.  句子嵌入的通用语言模型</h6><p>粗略地说，现有的通用语言模型主要是堆叠式递归变压器的变体，它包含数百万个可学习的参数。在投入使用之前，通用语言模型首先需要在极大的语料库（例如EnglishWikipedia）上进行预训练。 典型的预训练任务包括masked language model和下一句预测[17]。</p>
<p>为了获得给定句子的嵌入，需要遵循以下程序[17]：（1）根据准备好的词汇进行标记化（tokenization）；（2）token嵌入（即，借助可学习的查找表将token索引映射到相应的向量）；（3）通过Transformers沿两个维度传播。在最后一层，将句子被转化成<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600155062466.png" alt="1600155062466" style="zoom:50%;" />中长度为n的向量序列（即隐藏状态）；（4）最后，对隐藏状态执行合并操作以获取句子嵌入。通用语言模型的池化操作是将最后一层的最后一个隐藏状态作为句子的嵌入，因为大多数通用语言模型默认情况下都会在预训练阶段在输入句子的末尾添加一个特殊的标记（即<CLS>，直观地意味着要进行分类）。结果，使用最后的隐藏状态作为语句嵌入通常会带来更好的效用[17]，[44]。图1提供了上述过程的示意图。虽然对所描述的工作流的直觉表明应该在最后的隐藏状态中保留一定级别的上下文信息，但是我们的社区很少知道原始句子在编码中被保留到什么粒度，残留的敏感信息是否以及如何被潜在的攻击解码。</p>
<p><img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600156067062.png" alt="1600156067062"></p>
<p>图1.用于句子嵌入和潜在隐私风险的通用语言模型。 红色指示线说明了已发现的隐私风险：即使对手仅从通用语言模型中看到嵌入内容，对手也可以在未知的纯文本中重建一些敏感信息。</p>
<h6 id="C-In-the-Wild-通用语言模型"><a href="#C-In-the-Wild-通用语言模型" class="headerlink" title="C.  In the Wild 通用语言模型"></a>C.  In the Wild 通用语言模型</h6><p>如上所述，从头开始训练通用语言模型可能会非常昂贵。 作为替代方案，大多数最新模型都有在线发布的预培训版本以供免费访问。 在本文中，我们研究了由Google，OpenAI，Facebook和百度等行业领导者开发的8种主流语言模型。 表一列出了这些目标模型的基本信息。</p>
<h4 id="四-通用攻击管道"><a href="#四-通用攻击管道" class="headerlink" title="四. 通用攻击管道"></a>四. 通用攻击管道</h4><p>尽管最新的语言模型为获得用于各种下游任务的通用语义嵌入提供了直接有效的方法，但我们发现它们的改进的实用性伴随着隐秘的隐私风险。 通过构造两个新颖的攻击类别，我们展示了一个对手，可以对嵌入中未知明文中的各种敏感信息进行逆向工程。 在本节中，我们首先介绍一些有关攻击的一般说明。</p>
<h6 id="A-攻击定义"><a href="#A-攻击定义" class="headerlink" title="A. 攻击定义"></a>A. 攻击定义</h6><p>一般来说，在两种攻击中，对手都想从所访问的嵌入内容中推断出句子的一些敏感信息。在形式上，我们将攻击模型描述为<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600157303934.png" alt="1600157303934" style="zoom: 67%;" />，其中z是目标语句x的嵌入，s表示可以使用公知算法<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600157338335.png" alt="1600157338335" style="zoom:67%;" />从明文中获得的特定类型的敏感信息。例如，从治疗描述“头颅血管造影对比扫描”中，我们可以判断出患者可能患有疾病。在实践中，敏感信息可以有多种类型，从包含敏感信息的小段（即，P是取出整个序列的指定部分的操作）到纯文本x上的谓词。例如，在上面的案例中，P映射任何句子x到{0:1}：如果句子x中包含单词head，则P(x)=1；否则P(x)=0。这个概念被用于制定我们的攻击管道。</p>
<h6 id="B-威胁模型"><a href="#B-威胁模型" class="headerlink" title="B.  威胁模型"></a>B.  威胁模型</h6><p>通常，我们关注以下威胁模型。</p>
<ul>
<li>假设0。对手可以访问一组纯文本嵌入，其中可能包含对手感兴趣的敏感信息。</li>
<li>假设1。仅出于简单性考虑，我们 假设对手知道嵌入来自哪种类型的预训练语言模型。在第八节中，我们展示了可以使用提出的基于学习的指纹识别算法轻松消除此假设。</li>
<li>假设2。对手可以使用预训练语言模型作为预言机，该预言机以句子作为输入并输出相应的嵌入。</li>
</ul>
<p>对于每次攻击，我们还对对手对未知纯文本的先验知识施加不同的假设，这些假设在相应的部分中进行了详细说明。</p>
<h6 id="C-攻击管道"><a href="#C-攻击管道" class="headerlink" title="C.  攻击管道"></a>C.  攻击管道</h6><p>我们的一般攻击流程分为四个阶段。在第一阶段，对手准备一个外部语料库<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600158261422.png" alt="1600158261422" style="zoom: 67%;" />并且使用算法P提取<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600158301158.png" alt="1600158301158" style="zoom: 67%;" />作为标签。值得注意的是，由于外部语料库基本上是通过算法生成的，或者是从Yelp餐厅评论等开放域中爬取的，因此提取的标签通常不包含真正的敏感信息。在第二个阶段，对手用每个句子<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600158458679.png" alt="1600158458679" style="zoom: 67%;" />查询预先训练的语言模型，并得到他们的嵌入<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600158483168.png" alt="1600158483168" style="zoom: 67%;" />。在第三阶段，对手将嵌入内容与提取的标签进行组合，以训练攻击模型A。在最后阶段，对手使用训练有素的攻击模型从目标嵌入z中推断出敏感信息。图2概述了我们的攻击管道。 在下一部分中，我们将对管道中的每个阶段进行概述。</p>
<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600158600761.png" alt="1600158600761" style="zoom:80%;" />

<p><strong>步骤1：准备外部语料库。</strong>训练集的准备工作在前两个阶段完成。首先，由于攻击模型会以未知的明文推断敏感信息。因此，适当的外部语料库<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600158794864.png" alt="1600158794864" style="zoom: 50%;" />对于发挥成功的探测作用至关重要。基于明文上的不同知识水平，我们建议对手可以（1）通过生成算法来创建外部语料库或（2）从公开领域的公共语料库中生成。外部语料库中准备好后，我们对每一个<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600159007724.png" alt="1600159007724" style="zoom:50%;" />应用算法P得到标签<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600159031124.png" alt="1600159031124" style="zoom:50%;" />，从而结束了第一阶段。</p>
<p><strong>步骤2：查询语言模型。</strong>训练集准备的第二阶段是将<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600159107580.png" alt="1600159107580" style="zoom: 50%;" />中的句子转换为相应的嵌入。理想情况下，这很简单，因为对手只需要查询每个句子的语言模型即可。 在实践中，根据使用哪种模型的知识，对手可以在其设备上部署相应的预训练模型以进行本地查询。 对手还可以通过利用在线语言模型服务来节省一些预算[74]。在不失一般性的前提下，我们的评估是在以前的环境中进行的。 更多详细信息，请参见附录G。在此阶段的最后，我们得到<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600159277841.png" alt="1600159277841" style="zoom:50%;" />形式的训练集<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600159305832.png" alt="1600159305832" style="zoom:50%;" />，其中z是与句子x相对应的嵌入。</p>
<p><strong>步骤3：训练攻击模型。</strong>有了手头的训练集数据<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600159438225.png" alt="1600159438225" style="zoom:50%;" />，对手可以训练一个用于推理的攻击模型。通常，将模型设计为分类器，以嵌入信息z为输入，输出所有可能的敏感信息值的概率向量<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600159565515.png" alt="1600159565515" style="zoom:50%;" />。为了用准备好的数据集训练攻击模型，对手需要使用基于梯度的算法来解决以下优化问题，例如随机梯度下降（SGD）或者Adam，<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600159815774.png" alt="1600159815774" style="zoom:67%;" />，其中<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600159837760.png" alt="1600159837760" style="zoom:67%;" />是一个损失函数，用于测量预测概率与真实标签之间的差距。在本文中，<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600159892387.png" alt="1600159892387" style="zoom: 67%;" />始终将其作为交叉熵损失来实现。</p>
<p>最后要说的是，根据对手的知识水平，g架构在不同的环境中会有所不同。例如，知识渊博的攻击者会发现逻辑回归或线性SVM之类的现成分类器很好地工作，而没有先验知识的攻击者会利用高级迁移学习技术来成功进行攻击。</p>
<p><strong>步骤4：推断</strong>。在训练阶段之后，给定目标嵌入z，对手根据以下等式推断敏感信息：</p>
<p><img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600160273524.png" alt="1600160273524" style="zoom: 50%;" /><img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600160305162.png" alt="1600160305162" style="zoom:50%;" />，其中<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600160382658.png" alt="1600160382658" style="zoom:67%;" />是第i维的<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600160401643.png" alt="1600160401643" style="zoom: 67%;" />值，K表示s的可能值的总数。换句话说，对手将概率最高的值视为未知句子x中敏感信息的最可能值。</p>
<h4 id="5-模式重建攻击"><a href="#5-模式重建攻击" class="headerlink" title="5  模式重建攻击"></a>5  模式重建攻击</h4><p>在此部分中，我们着重于对手了解未知明文生成规则的情况，通常在明文格式为常识（例如身份代码）时发生。 我们以本节为起点来了解通用语言模型的嵌入中编码了多少敏感信息。</p>
<h6 id="A-攻击定义-1"><a href="#A-攻击定义-1" class="headerlink" title="A.  攻击定义"></a>A.  攻击定义</h6><p>直观地讲，模式重构攻击旨在恢复具有固定格式的纯文本的特定段。 目标片段可能包含敏感信息，例如出生日期，性别甚至基因表达。形式上，我们在以下假设下构建模式重构攻击。</p>
<ul>
<li><strong>假设3a</strong>。 明文的格式是固定的，并且对手知道明文的生成规则。</li>
</ul>
<p>按照IV-A节的一般说明，我们正式定义了从句子<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600221495565.png" alt="1600221495565" style="zoom:67%;" />中抽取敏感信息s的例程P<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600221599778.png" alt="1600221599778" style="zoom:67%;" />，其中b和e是目标段的起始和终止索引。假设P是总所周知的，那么对手也知道它。因此模式重构攻击w.r.t.<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600221804801.png" alt="1600221804801" style="zoom:50%;" /> 定义为<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600221824865.png" alt="1600221824865" style="zoom:50%;" /></p>
<p>具体来说，我们提供以下两个说明性实例。</p>
<p><strong>案例研究-公民身份证（缩写为citizen公民）。</strong>诸如身份代码或邮政编码之类的结构化信息通常出现在我们日常的对话中，并且这些对话被证明对于借助通用语言模型训练聊天机器人是有用的[55]。但是，我们发现，如果未正确清理邮件，则在给出句子嵌入的情况下，对手能够以较高的准确性恢复结构化信息，从而进行进一步的骚扰。例如，在许多国家/地区，公民ID是其所有者的典型敏感信息。 一旦泄露给对手，身份代码就可以用于访问受害者的其他敏感信息，或者允许对手冒充受害者参与非法活动[3]。为了说明这一点，我们以中国公民身份为例，它由18个字符组成（来自词汇表{0，…，9}），即居住代码（3000个可能性）为6，出生日期为8（大于100×12× 30个可能性）和4个额外的代码（10的四次方个可能性）。考虑到对手想要通过泄漏其公民身份证的嵌入来恢复受害者的确切出生日期，我们定义了映射P为<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600222247807.png" alt="1600222247807" style="zoom: 67%;" /></p>
<p><strong>案例研究-基因组序列（简称Genome基因组）。</strong>粗略地说，基因组是一个核苷酸序列，具有四种不同类型，即A，C，G，T作为其词汇。粗略地说，基因组是一个核苷酸序列，具有四种不同类型，即A，C，G，T作为其词汇。为了证明这一点，我们通过合并不同的通用语言模型实现了八个基准系统，用于剪接位点预测[45]，这是计算遗传学中的一个经典的二进制分类问题。基本上，我们的系统表现出很高的效用。 例如，使用Google的Bert的拼接点预测系统可实现超过75％的分类精度。 我们在附录的图8（a）中报告了我们系统的实用性，附录A中提供了更多详细信息。</p>
<p>然而，遗传数据以个性化的方式是高度敏感的-即使是在基因组序列中特定位置的核苷酸类型也可以与某种类型的基因疾病相关或表征种族信息[65]-因此对手很可能有兴趣恢复目标的准确核苷酸。从公开的核苷酸中，对手可以进一步了解受害者的性别，种族或其他对隐私至关重要的信息。为了演示，我们定义了映射P为<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600222771660.png" alt="1600222771660" style="zoom: 50%;" /><img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600222787568.png" alt="1600222787568">。换句话说，假定位置的核苷酸是敏感的。</p>
<h6 id="B-方法论"><a href="#B-方法论" class="headerlink" title="B.方法论"></a>B.方法论</h6><p>为了实现攻击<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600223417031.png" alt="1600223417031" style="zoom: 67%;" />，我们给出了外部语料库准备和攻击模型结构的实现细节。在接下来的部分中，我们表示序列<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600223445865.png" alt="1600223445865" style="zoom:67%;" />的所有可能值的集合。</p>
<p>1)生成外部语料库：知道目标明文的生成规则，对手可以通过生成算法来准备外部语料库。 基本生成算法通过从<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600223997003.png" alt="1600223997003" style="zoom:67%;" />的可能的值(即所有可能事件的集合)中随机采样来生成训练样本的批次。</p>
<p>2）攻击模型的架构：简单地说，攻击模型可以设计为具有输入维d和输出维<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600224091305.png" alt="1600224091305" style="zoom:67%;" />的全连接神经网络，即敏感段的可能值的数量。但是，<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600225411811.png" alt="1600225411811" style="zoom: 67%;" />可以非常大。例如，在公民案例中，可能的出生日期接近4万个，因此攻击模型中的自由参数将会很大，这进一步增加了批量生成和模型训练的难度。为解决此问题，我们根据对手对格式的了解，遵循分而治之的思想，将攻击模式<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600225559586.png" alt="1600225559586" style="zoom:67%;" />分解为小的子攻击。再次在公民案例中，我们可以将攻击模式<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600225678705.png" alt="1600225678705" style="zoom: 67%;" />分解为三个子攻击，命名为年攻击<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600225699433.png" alt="1600225699433" style="zoom:67%;" />、月攻击<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600225716097.png" alt="1600225716097" style="zoom:67%;" />和日攻击<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600225730731.png" alt="1600225730731" style="zoom:67%;" />。每个子攻击模型都可以使用更小尺寸发全连接神经网络独立实现，并且总参数从<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600225823456.png" alt="1600225823456" style="zoom:67%;" />到<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600225852711.png" alt="1600225852711" style="zoom:67%;" />大幅裁断。</p>
<h6 id="C-实验装置"><a href="#C-实验装置" class="headerlink" title="C. 实验装置"></a>C. 实验装置</h6><p><strong>基准系统</strong></p>
<ul>
<li>公民ID：我们根据等式1中的生成规则随机生成1000个公民ID，作为真实的纯文本。然后，使用这些公民ID查询目标语言模型，以获取对应的嵌入物作为受害者。</li>
<li>基因组：我们基于称为HS3D的公共基因组数据集（智人剪接位点数据集[53]）实现了八个基因组分类系统，用于剪接位点预测。 所有基因组序列的长度为20。 我们假设测试集中的基因组序列的嵌入被泄露给了对手，其中包含分别具有或不具有剪接位点的1000个样本。</li>
</ul>
<p><strong>攻击实施</strong></p>
<ul>
<li>公民ID：在第V-B节中讨论之后，我们将年，月和日子攻击实施为三层MLP，分别包含400、25、200个具有S型激活的隐藏单元。 每个子攻击的训练批次大小设置为128。</li>
<li>基因组：在实践中，我们通过将生成样本的嵌入z与目标位置i的位置嵌入pi连接起来来增加训练对<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600226365461.png" alt="1600226365461" style="zoom: 67%;" />。我们在附录B中讨论了动机。技术上讲，我们采用[72]中的正弦位置嵌入，其维度与z相同。对应于此修改，我们实现了一个单一的攻击模型来推断任何指定位置的核苷酸类型。 与市民ID情况不同，此修改不会增加参数，因为类别编号仍然为4。攻击模型实现为四层MLP，其输入是维数为2d的<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600226663843.png" alt="1600226663843" style="zoom:67%;" />，具有400,100个具有S型激活和中间批归一化层[32]的隐藏单元，以加快收敛速度。为了进行训练，我们生成了由128个元组（z，pi，wi）组成的大小为128的迷你批，其中位置嵌入是从可能位置的间隔（即1，…，20）中随机采样的。为了进行推断，攻击者输入了受害者的嵌入和目标位置，模型输出预测的核苷酸类型。更多实施细节可在附录B中找到。</li>
</ul>
<h6 id="D-结果和分析"><a href="#D-结果和分析" class="headerlink" title="D. 结果和分析"></a>D. 结果和分析</h6><p>表II报告了子攻击的Top-1和Top-5准确性，以及在100,000次训练后通过整体攻击推断整个出生日期的情况，其中基线表示随机猜测者的表现。 图3报告了100,000次训练后基因组攻击的平均和每核苷酸Top-1准确性，我们报告了最常出现的核苷酸类型的比例作为基线。</p>
<p><img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600239464399.png" alt="1600239464399"></p>
<p><img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600239571981.png" alt="1600239571981"></p>
<p><strong>1）效益和效率：</strong>从表II和图3，考虑基线的性能，我们可以看到我们的攻击可以有效地从嵌入中恢复敏感段。例如，当给定Transformer-XL(缩写。 XL在后面部分)嵌入公民ID，我们的攻击能够以超过80%的Top-1准确率恢复受害者的确切生日月份和日期，以超过62%的Top-5准确率恢复整个出生日期。当给定基因组序列的GPT嵌入时，我们的攻击实现了在两端推断受害者核苷酸类型的接近100%的准确率，平均超过62%的准确率。当给定基因组序列的GPT嵌入时，我们的攻击实现了在两端推断受害者核苷酸类型的接近100%的准确率，平均超过62%的准确率。</p>
<p>此外，就吞吐量而言，我们的攻击也很有效，如附录表VI所示。 在两种情况下，攻击都可以在一秒钟内从超过100个批次中学习。 为了达到所报告的准确性，在中型PC上进行的培训时间不超过30分钟。 我们的实验环境的更多细节在附录H中。</p>
<p><strong>2）语言模型之间的比较：</strong>首先，我们注意到Facebook的RoBERTa在这两种情况下均显示出比其他语言模型更强的鲁棒性。通过研究其设计，我们发现RoBERTa是Google Bert的重新实现，但是使用不同的字节级标记化方案（即，以字节为单位的标记化句子而不是字符或单词）[44]。由于RoBERTa在面对相同的攻击时显示的隐私风险比Bert低约50％，因此我们推测原因是字节级标记化方案可能使嵌入在字符级敏感信息中不那么明显，从而对我们的攻击更具鲁棒性。下一节中也观察到类似的现象。但是，RoBERTa遭受了明显的效用下降，这是效用与隐私之间的权衡。从图6（c）中可以看出，与在基因组上使用RoBERTa的系统相比，使用Bertachieve的系统的效用性能高约33％。此外，我们注意到OpenAI的GPT和GPT-2具有相同的体系结构，但已在4GB和40GB文本上进行了预训练，在抵御我们的攻击和类似的实用程序性能方面显示出类似的安全特性。结合其他结果，预训练数据大小和隐私风险级别之间没有直接的关联性。</p>
<p><strong>3）其他有趣的发现：</strong>从图3中，我们可以看到，大多数精度曲线呈现谷状形状，这意味着大多数语言模型比中间的捕获更多的token信息，这可能是由于末端信息通常沿着递归架构中的最长路径传播。从图3中，我们可以看到，大多数精度曲线呈现谷状形状，这意味着大多数语言模型比中间的捕获更多的令牌信息，这可能是由于信息所致。 末端通常沿着循环架构中的最长路径传播。</p>
<h4 id="6-关键字推断攻击"><a href="#6-关键字推断攻击" class="headerlink" title="6  关键字推断攻击"></a>6  关键字推断攻击</h4><p>在本节中，我们研究一个更一般的情况，即纯文本可以是任意自然句子，而对手的知识水平要低得多。 结果，在这种情况下成功的攻击可能会对现实世界的系统构成更大的威胁。</p>
<h6 id="A-攻击定义-2"><a href="#A-攻击定义-2" class="headerlink" title="A. 攻击定义"></a>A. 攻击定义</h6><p>关键字推理攻击的对手对以下谓词感到好奇，无论某些关键字k是否包含在未知句子x中。关键字可以是高度敏感的，其包含供对手进一步确定例如受害者的位置、住所或病史的指示符[62]。在介绍两个说明性示例之前，我们首先构造了映射<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600241508334.png" alt="1600241508334" style="zoom: 50%;" />，为了定义句子x中与关键词k相关的敏感信息</p>
<p><img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600241533412.png" alt="1600241533412" style="zoom:50%;" /><img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600241573619.png" alt="1600241573619" style="zoom:50%;" /></p>
<p>其中右侧表示一个预测，即如果一个单词w在句子x中是目标关键字，则为true；否则为Fasle。k作为对手指定的关键字，例程<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600241900537.png" alt="1600241900537" style="zoom:50%;" />是他/她明显知道的。相应的，关于<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600241996656.png" alt="1600241996656" style="zoom:50%;" />的关键字推断攻击定义为<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600242011268.png" alt="1600242011268" style="zoom: 50%;" /><img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600242051005.png" alt="1600242051005" style="zoom:50%;" /></p>
<p>与模式重建攻击不同，关键字推理攻击会探究某些关键字的出现，而不是整个序列的精确重构。</p>
<p><strong>案例研究-航空公司评论（缩写为航空公司）。</strong>有时航空公司调查他们的客户，例如，为了改善他们的客户服务。借助先进的NLP技术，可以自动处理大量文本形式的航空公司评论，以了解客户的观点（即观点挖掘[69]）。众所周知[16]，[17]，[41]，利用经过预训练的语言模型进行特征提取可以进一步提高许多现有观点挖掘系统的实用性。</p>
<p>但是，一旦访问了嵌入内容，对手就可以推断出与受害者有关的各种与位置相关的敏感信息，包括他/她的离开，居住，行程等。作为进一步攻击的初步步骤，我们证明了对手可以准确地估算出是否有特定城市名称的可能性 包含在评论中。</p>
<p><strong>案例研究-医学描述（缩写为医学）。</strong>随着智能医疗保健的兴起，一些医院倾向于建立自动的预诊断系统以提高服务质量[28]。 该系统将根据患者的病情描述来预测他/她应咨询的科室。为了形成一个基准系统，我们将预先训练好的语言模型与一个附加的线性层连接起来，以指导患者进入10个不同的科室。通过评估，我们在附录的图8（b）中显示系统可以在真实数据集上实现90％以上的准确性，更多详细信息可以在附录A中找到。</p>
<p>但是，当对手只能访问嵌入内容时，他/她确实可以推断出有关患者作为受害者的更敏感和个性化的信息。 除了患者应咨询的部门之外，对手还可以确定其他细粒度的信息，例如疾病类型甚至确切的疾病部位。 为了说明这一点，我们假设一个对手想通过推断其描述中与身体相关的单词的出现概率来确定受害者的确切疾病部位。</p>
<h6 id="B-方法论-1"><a href="#B-方法论-1" class="headerlink" title="B. 方法论"></a>B. 方法论</h6><p>在这一部分中，我们将详细介绍关键字推断攻击的实现。根据作者对纯文本知识的不同层次，方法论部分分为白盒和黑盒两种设置，分别需要以下两种假设。</p>
<ul>
<li><strong>假设3b。</strong>敌手可以访问半个（shadow）语料库，该语料库由从相同分布的目标纯文本(我们称之为白盒)中抽取的句子组成。</li>
<li><strong>假设3c。</strong>对手没有目标纯文本（我们称为黑匣子）的信息。</li>
</ul>
<p>值得注意的是，假设3c中的对手几乎没有先验知识，只是他/她（例如，捕获嵌入的任何攻击者）都可以访问嵌入，因此对通用语言模型构成了相当实际的威胁，而假设3b也可能 当在现实世界中发生这种情况时，如果继续我们上面的医学示例，某家医院出于研究目的发布了医学描述的匿名数据集[1]，或者服务提供者是诚实但好奇的。</p>
<p><strong>白盒攻击设计</strong>。基本上，对手有个影子语料库<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600254282140.png" alt="1600254282140" style="zoom:50%;" />，是从与未知纯文本相同的分布中抽取的。他/她可以直接使用<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600254461985.png" alt="1600254461985" style="zoom: 50%;" />作为外部语料库<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600254487468.png" alt="1600254487468" style="zoom: 50%;" />并且抽取二进制标签<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600254519469.png" alt="1600254519469" style="zoom: 50%;" />。接下来，对手用数据集训练一个二进制（二元）分类器来处理<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600254609193.png" alt="1600254609193" style="zoom:50%;" />。但是我们注意到在实践中，对手可能会遇到一些陷阱。</p>
<p>首先，标签集<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600254800364.png" alt="1600254800364" style="zoom:50%;" />可能非常不平衡。换句话说，与没有k的关键词（即，否定样本）相比，具有关键词k（即，正样本）的句子可能是绝对少数。根据先前的研究，标签的不平衡将使攻击模型易于拟合，从而阻碍攻击的性能[33]。为了缓解这种情况，我们建议用关键字将负样本中的某些单词随机替换为关键字，并用词汇表中的其他随机词替换正样本中的关键字（称为单词替换技巧）。</p>
<p>下一步，单词替换后的影子语料库在大小上仍然可以限制，即，N是小的。在这种情况下，我们建议对手使用SupportVector Machine（SVM）实施攻击模型，这对于小样本学习特别有效[71]。当M大于特定阈值时（经验超过10的三次方个样本），对手可以切换到完全连接的神经网络作为攻击模型，从而提高了攻击准确性。</p>
<p><strong>攻击黑盒设计。</strong>假设3c下的对手面临最富挑战性的情况，因为他/她之前对纯文本几乎没有任何了解。 反过来，在这种一般情况下成功的攻击将对通用语言模型的隐私性构成巨大威胁。</p>
<p>为了在没有先验知识的情况下实现关键词推理攻击，我们提出先从互联网上抓取句子形成外部语料库，然后将攻击模型在外部语料库上的对抗性知识动态地传递到目标语料库。 详情如下。</p>
<p>1）从公共语料库创建外部语料库：借助互联网，对手从其他公共语料库中获取外部语料库相对较为方便。 接下来，对手可以通过我们在上一部分中提到的相同单词替换技巧生成正样本和负样本。</p>
<p>2）传递对抗性知识：在初步尝试中，我们发现如果我们直接在外部语料库上训练现成的分类器（例如线性SVM或MLP），然后使用它对目标嵌入进行关键字推断攻击，则攻击的准确性有时会变差。 我们推测是导致此现象的是域未对准。为了进行验证，我们首先在外部语料库上训练了一个三层MLP分类器。 关键字头，它是从Yelp-Food数据集（即由餐厅评论组成的数据集）中准备的。我们还在图4（b）中的包含1000个句子的目标医学数据集上绘制了分类器的预期决策边界，其中散点绘制了经过主成分分析（PCA）和尺寸缩减后的XLNet嵌入在隐藏层的中间表示。 两种颜色表示纯文本是否包含标题。如我们所见，两个决策边界几乎彼此正交。结果，即使在公共领域（即在餐厅评论中）的攻击模型达到了接近100％的准确性，但是当其在私有领域（即在医学描述上）应用时，其性能也不比随机猜测好。</p>
<p><img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600257476789.png" alt="1600257476789"></p>
<p>图4.通过外部语料库上训练的MLP分类器的（预期）决策边界的镜头，（a）外部语料库与（b）目标语料库之间的域未对齐。</p>
<p>通常，这里的主要挑战是如何将攻击模型学到的对抗知识从公共领域（例如Yelp-Food数据集）转移到私有领域（例如医学数据集）。首先，我们介绍一些基本的符号。我们分别将公共域和私有域表示为<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600257690863.png" alt="1600257690863" style="zoom:50%;" />。从X中给定一个训练集<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600257814867.png" alt="1600257814867" style="zoom:50%;" />并且从Y中给定目标嵌入<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600257869406.png" alt="1600257869406" style="zoom:50%;" />对手想要训练一个在<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600257985699.png" alt="1600257985699" style="zoom:50%;" />上表现良好的攻击模型<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600258003371.png" alt="1600258003371" style="zoom:50%;" />。当<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600258094296.png" alt="1600258094296" style="zoom:50%;" />分散分布时，直接的方法效果不佳，因此出现图4中的现象。</p>
<p>因此，我们建议从Dprivate和Dpublic学习用于嵌入的统一的不变域表示。为了实现这一点，我们受到领域对抗神经网络(DANN)[9]的启发，并在图5中提出了我们的攻击模型的体系结构。</p>
<p><img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600258299480.png" alt="1600258299480"></p>
<p>该模型包含四个子模块。 首先，模块E是一个编码器，将句子嵌入作为输入，并期望输出一个域不变表示ˆz。隐藏的表示形式后面是两个二进制分类器，即<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600258379374.png" alt="1600258379374" style="zoom:50%;" />。关键字分类器<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600258566575.png" alt="1600258566575" style="zoom:50%;" />接收ˆz作为输入，并且预测句子x是否包含关键字k。而域分类器<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600258610036.png" alt="1600258610036" style="zoom:50%;" />输出是否嵌入来自<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600258629773.png" alt="1600258629773" style="zoom:50%;" />。在实践中，我们实现E为Sigmoid激活的非线性层，实现<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600258843073.png" alt="1600258843073" style="zoom:50%;" />两个线性层，然后是Softmax层。对于这两个分类器，损失被计算为输出与真实之间的交叉熵。此外，<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600259096125.png" alt="1600259096125" style="zoom: 33%;" />的损失是在<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600259131755.png" alt="1600259131755" style="zoom:33%;" />上计算的，<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600259072831.png" alt="1600259072831" style="zoom: 33%;" />的损失是在<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600259048117.png" alt="1600259048117" style="zoom: 33%;" />上计算的。</p>
<p>在我们的实现中，称为梯度反转层[9]的附加模块是学习领域不变表示的基础，因此有助于传递对抗性知识。梯度反转层位于域分类器和隐藏表示的中间，后者在转发阶段充当身份层，并在反向传播阶段通过在每个坐标上放置负号来反转梯度。直观地说，梯度反转层通过放大与关键字相关的特征和消除与域相关的信息来规则化隐藏的表示ˆZ。附录一中的算法1详细介绍了基于DANN的攻击模型的学习过程中的典型情况。 为了进行推断，我们将<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600259445080.png" alt="1600259445080" style="zoom:50%;" />作为攻击模型g。</p>
<h6 id="C-实验设置"><a href="#C-实验设置" class="headerlink" title="C.  实验设置"></a>C.  实验设置</h6><p>我们在航空公司和医疗公司的两个案例研究中，在白盒和黑盒设置中评估了建议的关键字推理攻击。</p>
<p><strong>基准系统</strong></p>
<ul>
<li>航空公司：我们从Skytrax [5]收集航空公司评论数据集，并保留包含10个指定城市名称（例如，曼谷，法兰克福等）之一的评论，以形成基准数据集。预处理后的数据集包含4685条航空公司评论（平均长度15），我们将数据集随机分成10:1，得到测试集和阴影数据集，用于模拟白盒设置。我们选择阴影集为更小的分区，以便更好地模拟真实的情况。然后，我们用测试集中的评论查询目标语言模型，并获得嵌入作为受害者。在黑匣子设置中，对手仅访问测试集的嵌入内容以进行对抗性知识转移。 我们假设将对手的关键字设置为出现的10个城市名称。</li>
<li>医疗公司：我们基于CMS公共医疗记录实施了八个预诊断系统[1]。 这些系统旨在根据患者疾病的文字说明将其引导至适当的部门。我们在附录A中报告了基准系统的实用程序和更多的实现细节。他预处理了数据集，包含平均长度为10的12万种疾病描述。我们将数据集随机分成10：1，以形成测试集和阴影数据集。我们使用测试集中的描述查询目标语言模型以形成目标集。 我们假设对手的关键字集包含出现在数据集中的10个与身体相关的词（例如，头，脚等）。</li>
</ul>
<p><strong>衡量标准</strong>   为了进行评估，我们为每个目标关键字准备了均衡测试集。详细地说，我们将包含测试集中关键字的所有句子的嵌入保留为阳性样本，并从其余测试集中随机抽取与阴性样本相同数量的嵌入。每个测试集的统计信息在附录H中。我们以准备好的测试集的分类准确性来衡量每个关键字的攻击效果。为了确保攻击的有效性不是由对手知道哪个关键词来引起的，我们还对航空公司和医疗公司的DANN进行了黑盒攻击，以推断目标语料库中不包含的5个随机关键词。</p>
<p><strong>黑盒设置中的外部语料库。</strong>按照第VI-B节中的程序，我们从Yelp-Food数据集中为黑盒设置创建外部语料库，该数据集包含客户对本地餐馆的评论，医疗或航空公司的常用词少于20％，可以替换为 其他公共语料库。具体地说，我们选择了2000个包含单词salad的样本，并分别为每个关键词推理攻击准备了2000个正样本和2000个负样本。</p>
<p><strong>攻击实施</strong></p>
<ul>
<li>白盒设置：我们研究了白盒设置下攻击模型的两种实现，即线性支持向量机和具有80个隐含单元的3层Sigmoid激活的MLP。 批量大小设置为64。</li>
<li>黑盒设置：我们研究了黑盒设置中的三种实现，即线性SVM，3层MLP和基于DANN的攻击。 DANN模型具有25维域不变表示，并且将算法1中的系数λ设置为1。 对于MLP和基于DANN的攻击，我们都使用学习率为0.001的Adamoptimizer。 批处理大小设置为64。</li>
</ul>
<h6 id="D-结果和分析-1"><a href="#D-结果和分析-1" class="headerlink" title="D. 结果和分析"></a>D. 结果和分析</h6><p>图6（b）和（f）报告了分别在航空公司和医疗公司具有不同攻击模型的白盒和黑盒设置中关键字推理攻击的性能。 结果平均为10个关键字。我们还在图6（a）和（e）中针对每个关键字提供了基于DANN的攻击的准确性。由于Dann的博弈论本质，我们注意到基于Dann的攻击的准确性随着时间的推移而动态变化。我们在50个时期内报告了基于DANN的攻击的平均和最佳准确性，以反映平均和最坏情况下的隐私风险。 对于基线方法SVM和MLP，我们在学习过程收敛后报告其准确性。</p>
<p><strong>1）效用和效率：</strong>这些实验结果很好地证明了我们的攻击在白盒和黑盒环境下的有效性。 例如，从图6(F)中我们可以看到，我们的白盒攻击，考虑到Bert嵌入了受害者的医学描述，在推断特定身体部分的发生时达到了99%以上的准确率，而我们的黑盒攻击在没有先验知识的情况下，平均仍然可以达到75%以上的准确率。同样，当给定受害者航空评论的GPT和GPT-2嵌入时，我们的白盒攻击和黑盒攻击对于推断特定城市名称的出现平均分别达到95%和75%以上的准确率。我们还在表III中报告了基于Dann的攻击对航空公司和医疗公司的准确性，当推断目标语句中没有包含的5个随机关键字时，我们也报告了基于Dann的攻击对航空公司和医疗公司的准确性。 正如我们所看到的，我们的黑盒攻击在大多数情况下达到了90%以上的平均准确率。此外我们在表VI中报告了训练攻击模型的吞吐量，这表明可以在不到2分钟的时间内有效构建攻击。结合上一节中模式重建攻击的成功，这些发现进一步支持了我们的主要发现，即这8种目标语言模型的嵌入中编码了很多敏感信息，并且实际上可以反向工程化形式化目的。</p>
<p><strong>2）语言模型比较</strong>：从图6（b）中我们注意到，面对我们在航空公司上的白盒攻击时，Google的XL和Facebook的RoBERTa的鲁棒性比其他语言模型强得多。对于这两种模型，我们的白盒攻击仅在轻度裕度下优于随机猜测器，而在医疗方面，白盒攻击旨在当对其他模型的攻击统一超过95％时，这两个模型可实现约80％的准确性。这种现象暗示着XL中的敏感信息，而RoBERTa的嵌入变得更加难以逆向工程，我们推测主要原因是XL的预训练数据量相对较小（因此词汇量也较小[16]）以及RoBERTa的字节级token化方案 。结果，线性支持向量机没有足够的学习能力[71]来利用其嵌入的敏感信息，而基于MLP的攻击却因有限的样本量在航空上而遭受不足的困扰（在航空上约2000例，在航空上约400例）。但是，结合图6（g），在Medical for XL上观察到了轻微的效用-隐私权衡，这表明效用比Bert达到的最佳效用性能低约7％，而没有观察到效用-隐私权衡。 对于RoBERTa，这可能是因为我们大多数系统的效用性能都很高（超过90％），因此效用差异不是很明显。</p>
<p><strong>3）攻击实现之间的比较：</strong>首先，比较图6（b）和（f）的每个条形组的左两列和右三列，我们可以看到，一般来说，白盒攻击比黑盒对手更有效。例如，我们注意到Medical上的白盒攻击平均比黑盒攻击高出25%，而我们在上面讨论过的Roberta和XL则例外。接下来，在黑盒攻击中，MLP和Dann攻击在许多配置中表现出类似的效果。 然而，对于Facebook的XLNet onMedical，MLP攻击的准确率仅为0.560，这与图中的域未对齐相对应。 4，而Dann方法将攻击的准确率平均提高到0.601，在最坏的情况下提高到0.691。最后，我们还考察了Dann攻击对每个关键字的性能。 出自图2。 6(A)和(E)，我们可以看到不同的语言模型有其特别易受攻击的关键字。例如，从Google的Bert嵌入内容推断出词霸时，基于DANN的攻击获得了95％以上的准确性，而从百度的ERNIE嵌入物中推断出踝部时，则达到了80％以上的准确性。 我们希望在以后的工作中调查这种有趣现象的根本原因。</p>
<p><strong>4）消融研究：</strong>我们还通过对OpenAI的GPT-2的三种变体（即GPT-2，GPT-2-Medium，GPT-2-Large）的各种配置下的关键字推理攻击进行调查，来进行全面的消沉研究，在相同的语料库上预训练的，但是参数数字和嵌入维度增加[55]。 详细的统计数据可在附录H中找到。</p>
<p>首先，我们研究了外部语料库大小对攻击效果的影响：(1)对于白盒设置，我们在{10,100，…，1000}中改变代表白盒设置中对手知识水平的影子语料库的大小，并对Medical进行MLP攻击。结果在图6（c）中提供。 我们可以看到，当阴影语料库的大小大于100时，每种语言模型的攻击准确率仍会超过90％。 此外，有趣的是，当对手的知识受到限制时，较大的语言模型（GPT-2-Large）不如较小的语言模型健壮。当影子语料库大小仅为10时，针对GPT-2-Large，GPT-2-Medium和GPT-2的攻击准确度分别为68.5％，61.0％和59.4％。 该观察结果也与[34]中的结论一致：复杂的模型倾向于扩大攻击面。（2）同样，对于黑盒设置，我们通过将外部语料库的大小从原始大小2000的100％更改为5％来比较DANNattack的表现，结果如图6（d）所示。 如我们所见，更大的外部语料库有助于我们的攻击获得更高的准确性，这证明了我们提出的对抗性知识转移程序的有效性。</p>
<p>此外，我们还研究了DAN攻击的鲁棒性。 其超参数。 我们分别控制受害者嵌入的大小（与黑箱设置中的对手的知识水平相对应）以及DANN中域不变表示的大小（这是DANN的唯一体系结构因素），并进行DANN进攻。对于这两个设置，我们分别在图6（g）和（h）中报告攻击准确性。 如图所示，使用不同的超参数选择，DANN攻击的准确性仍然很高，这在很大程度上反映了我们提出的攻击模型的鲁棒性和有效性。</p>
<p><img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600263197551.png" alt="1600263197551"></p>
<p><img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600263252389.png" alt="1600263252389"></p>
<h4 id="7-可能的防御"><a href="#7-可能的防御" class="headerlink" title="7  可能的防御"></a>7  可能的防御</h4><p>由于句子嵌入是潜在信息泄漏的直接来源，因此消除嵌入的一般原则是对嵌入进行模糊处理。为此，我们根据经验评估了四个可能的技术选择，其中前三个是针对两种攻击的通用选择，而最后一个是针对关键字推理攻击而专门设计的。尽管理想的情况是可以完全消除敏感信息，同时可以高度保留其他正常任务所需的信息，但实际上，至少在下面我们报告的权衡结果中，这样的效用-隐私权衡似乎是不可避免的。在这里，效用表示基础基准系统的分类准确性。 我们希望我们的初步研究将促进未来的缓解研究。 省略的技术细节和实验设置可以在附录C中找到。</p>
<p><strong>（1）舍入。</strong>对于第一道防线，我们在句子嵌入的每个坐标上应用浮点舍入以避免混淆。正式地，我们将舍入防御写为<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600263422709.png" alt="1600263422709" style="zoom:50%;" />rounding(z,r)，其中非负整数表示四舍五入后保留的小数位数。</p>
<p><strong>（2）拉普拉斯机制。</strong>对于第二种防御，我们利用了差分隐私方法，即拉普拉斯机制[20]。粗略地讲，我们用来自Laplace分布的样本来干扰嵌入坐标，该样本的参数由语言模型f的<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600263886866.png" alt="1600263886866" style="zoom:50%;" />确定（表示为Δf，我们用数值算法对其进行了估计）。正式地，防御工作为<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600264175785.png" alt="1600264175785" style="zoom:50%;" />，其中<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600264492510.png" alt="1600264492510" style="zoom:50%;" />和<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600264543305.png" alt="1600264543305" style="zoom:50%;" />是在<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600264200355.png" alt="1600264200355" style="zoom:50%;" />随机采样的样本，Laplace分布位置为01，比例为<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600264562351.png" alt="1600264562351" style="zoom:50%;" /></p>
<p><strong>（3）隐私保护映射。</strong>第三种防守是以对抗性训练为基础的。 我们借用了文献[57]中的隐私保护映射的概念来表示<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600264971943.png" alt="1600264971943" style="zoom:50%;" />由θ参数化，其目的是最小化想象中的对手Aψ的有效性。同时，要求PPM通过仅在围绕原始嵌入的有限半径内扭曲嵌入来遵循效用约束，这被实现为细化术语。形式上，我们建议通过求解下列极小极大<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600264888640.png" alt="1600264888640" style="zoom:50%;" />来学习隐私保护映射<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600265060138.png" alt="1600265060138" style="zoom:50%;" />，其中<img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600265012931.png" alt="1600265012931" style="zoom:50%;" />控制隐私级别，越高的隐私级别越低。</p>
<p><strong>（4）子空间投影。</strong>最后的防御是专门针对关键字推理攻击而设计的，[14]启发了从性别偏见中消除词嵌入的偏见。这种防御的总体思路是从通用句子嵌入空间中投影出不需要的子空间（即隐私子空间），该子空间对关键字的出现进行编码。有关如何识别隐私子空间以及如何进行投影的技术细节，请参见附录C。在评估中，我们将隐私子空间的维数与泛嵌入空间的维数之比β作为该防御的参数，期望更高的β会带来更严格的隐私机制。</p>
<p><strong>评估。</strong>我们评估了前三个防御措施，以防止针对Genome的模式重构攻击以及针对具有多种设置的Medical的基于DANN的关键字推理攻击的所有四种防御措施。前三个防御的配置和结果如图7所示。</p>
<p>从图7中可以看出，尽管在一定的私密性预算下，每种防御都可以将攻击者削弱为一个完全随机的猜测者，但它们同时会通过造成令人无法接受的降级而损害下游任务的效用。例如，当达到最佳防御性能时，拉普拉斯机制也会将实用程序降级为完全随机猜测器。对于PPM，尽管观察到了较小的取舍，但当实现最佳防御时，RoBERTa和Transformer-XL的实用程序仍会从90％以上降为25％。在这些防御中，我们注意到子空间投影防御可以提供比三种可能的防御更理想的防御质量。 例如，对于大多数目标语言模型，防御只能通过仅投影与关键字有关的1％子空间来将DANN攻击降级为随机猜测者。但是，与未保护嵌入的95％准确性相比，在下游任务上嵌入的效用仍降低了约15％，这意味着我们要隐藏的关键字对于为下游任务提供必要的语义也是至关重要的。 而且，由于子空间防御者对对手感兴趣的目标关键词不了解，因此在实践中，子空间防御的质量也不太理想。</p>
<p><img src="C:\Users\薛晓萱\AppData\Roaming\Typora\typora-user-images\1600305601354.png" alt="1600305601354"></p>
<p>根据我们上面的初步结果，如何平衡从嵌入中消除令牌级别的敏感信息和保留正常任务所需的基本信息仍然是一个尚待进一步研究的悬而未决的问题。 考虑到我们对通用语言模型应用的攻击所带来的实际威胁，我们强烈建议探索有效的防御机制作为未来的工作。</p>
<h4 id="8-讨论"><a href="#8-讨论" class="headerlink" title="8 讨论"></a>8 讨论</h4><p>在威胁模型上：对于假设0，如果将通用语言模型部署在协作或联合学习系统中，则对手可以获取受害者的句子嵌入，尤其是在以下情况下：a）服务提供者本身想监听用户的敏感信息，或者b）意外共享嵌入物或 虐待恶意攻击者。在最近的一些协议中，可以使用同态加密方案对特征进行加密以保护隐私[24]，因此需要广告者首先使用公钥对外部语料库的嵌入进行加密，然后在加密的外部语料库上训练攻击模型。 这是一个有趣的场景，值得进行专门研究，我们将其留作未来工作。然而，由于效率问题，还有许多不适合同胚加密方案的场景，例如实时长途翻译[75]或具有语言模型的搜索引擎[6]。 在这些情况下，我们的攻击仍然是巨大的威胁。</p>
<p>对于假设1，我们设计一种基于学习的指纹算法，方法是首先基于维度大小确定候选模型类型，然后使用预先训练的分类器精确定位精确模型类型。 令人惊讶的是，我们发现分类精度可以达到100％。 更多技术细节和分析可以在附录D中找到。</p>
<p>对于“假设2”，对手可以通过在本地设备上部署语言模型或访问相应的在线服务来轻松满足假设。 在当前的工作中，我们考虑到攻击的普遍性采用了这种假设。 尽管如此，对手仍可以进一步利用特定的语言模型体系结构和预先训练的参数来提高攻击效率，这是未来工作中一个有趣且有意义的方向。</p>
<p><strong>下游攻击：</strong>正如我们在第V和VI节中提到的那样，我们提出的攻击可以进一步用于可能造成更严重后果的下游攻击。 例如，如果攻击者由于某种原因而嵌入了“头颅血管CT扫描”处理描述，则他/她可以利用提议的关键字推理攻击来推断定制词汇中每个单词的出现概率（例如， 词汇中包含head和vessel，因为它们是医学上的常用词，以降序对出现概率进行排序（例如，两个单词head andvessel的出现概率均高于90％），从而使句子的含义颠倒（例如，患者可能患有某些异常情况） 他头部的血管）。附录E提供了实施上述指南的演示性实验。 我们发现，即使某些单词可能不在定制的词汇表中，对手也确实可以通过上述过程重新组合原始文本的基本语义。</p>
<p><strong>部署句子嵌入时的效用与隐私</strong>。我们目前的工作表明，通用语言模型中的句子嵌入的改进效用与隐私不符。 原则上，为了平衡实用程序-隐私权衡，需要嵌入句子以保留下游任务所需的信息并丢弃其余任务，而通用语言模型会遇到以下难题：这些模型专门旨在提供可用于各种下游任务的嵌入[17]，从而强制执行嵌入以保留许多令牌级别的信息，这在许多情况下对于形成语义至关重要，因此为对手提供了进行隐私泄露的窗口。根据我们对八种最新语言模型的系统评估，我们发现字节级标记化方案确实可以通过设计提供额外的隐私保护。 同时，通过对抗训练或子空间投影来模糊句子嵌入可能是未来研究的有希望的方向，因为它们可以实现更理想的效用-隐私权衡。</p>
<p><strong>局限性和未来工作。</strong>尽管我们已经观察到不同语言模型的安全性方面存在一些有趣的差异，但对于网络深度，学习算法和超参数等其他许多设计选择是否会影响相应的设计，我们仍然不清楚。 刺耳的语言模型的隐私级别。 我们有兴趣在以后的工作中研究这些问题。此外，尽管我们对四种可能的防御措施进行了初步研究，但我们发现它们都无法在下游任务的隐私和效用之间实现最佳平衡。 同样，由于硬件的限制，我们还没有评估不同的私人训练技术（例如DPSGD [7]）的防御质量。我们希望我们的工作能引起研究人员的更多关注，以便对隐私属性进行更深入的研究。 这种新的NLP范例以及相应的缓解方法。</p>
<h4 id="九-结论"><a href="#九-结论" class="headerlink" title="九 结论"></a>九 结论</h4><p>在本文中，我们设计了两种新颖的攻击类别，即模式重构攻击和关键字推理攻击，以说明从句子嵌入中窃取敏感信息的可能性。 我们对八种行业级语言模型进行了广泛的评估，以从经验上验证这些隐私威胁的存在。 为了阐明未来的缓解措施研究，我们还通过混淆句子嵌入以减弱敏感信息来提供四种防御方法的初步研究。 据我们所知，我们的工作是对通用语言模型的隐私风险以及可能的对策进行的首次系统研究。 为了将来在现实世界中利用最先进的NLP技术，我们希望我们的研究能够引起更多研究兴趣和对通用语言模型的安全性和隐私性的努力。</p>
	
		</div>
		
		<div id="current-post-cover" data-scr="/img/cart_cover.jpg"></div>

		<!-- relate post, comment...-->
		<div class="investment-container">
			<div class="investment-header">
				<div class="investment-title-1">
					<div class="on">相关文章</div>
					<div>评论</div>
					<div>分享</div>
				</div>
				<div class="investment-title-2">	            
					
	<span>
		<a id="totop-post-page">返回顶部</a>
		
			
	</span>


      		
				</div>	
			</div>
			
			<div class="investment-content">
				<div class="investment-content-list">
					

<div class="relate-post">
	
		<div class="config-info">
			Please check the parameter of <b>post_relate</b> in config.yml of hexo-theme-Annie! You should make sure that <b>postsEnable is true</b> and the number of site posts greater than 1.
		</div>	
	
</div>	
				</div>
				<div class="investment-content-list">
					<div class="layout-comment">

	
		<div class="config-info">
			Please check the parameter of <b>comment</b> in config.yml of hexo-theme-Annie!
		</div>	
	

</div>
				</div>
				<div class="investment-content-list">
					<div class="layout-share">
	
	

		
			
			<!-- socialShare share -->
			<div class="social-share"></div>

<!--  css & js -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">
<script async src="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>
			
		
		
	
</div>


				</div>
			</div>	
		</div>
	</div>
</div>

<!-- show math formula -->



	 
	
<script src="/plugin/clipboard/clipboard.js"></script>

	<script>
		// Copy code !
	    function preprocessing() {
	        $("#article-content .highlight").each(function() {
	            $(this).wrap('<div id="post-code"></div>');
	        })

	        $("#article-content #post-code").each(function() {
	            $(this).prepend('<nav class="copy-nav"><span><i class="code-language"></i></span></nav>');
	        })

	        $("#article-content .copy-nav").each(function() {
	            let languageClass = $(this).next().attr('class'),
	                language = ((languageClass.length > 9) && (languageClass != null)) ? languageClass.substr(10) : "none"; //why 9? Need to check language?

	            $(this).find('.code-language').text(language);
	            $(this).append('<span class="copy-btn icon-paste"></span>');
	        });
	    }

		function copy() {
		    $('#article-content #post-code').each(function(i) {
		        let codeCopyId = 'codeCopy-' + i;

		        let codeNode = $(this).find('.code'),
		            copyButton = $(this).find('.copy-btn');

		        codeNode.attr('id', codeCopyId);
		        copyButton.attr('data-clipboard-target-id', codeCopyId);
		    })
   
			let clipboard = new ClipboardJS('.copy-btn', {
					target: function(trigger) {
						return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
					}
		      	});

			//pure js
			function showTooltip(elem, msg) {		   
				elem.setAttribute('aria-label', msg);
				elem.setAttribute('class', 'copy-btn icon-clipboard1');
				setTimeout(function() {
					elem.setAttribute('class', 'copy-btn icon-paste');
				}, 2000);
			}

			clipboard.on('success', function(e) {
			    e.clearSelection();
			    console.info('Action:', e.action);		   
			    console.info('Trigger:', e.trigger);
			    showTooltip(e.trigger, 'Copied!');   
			});
			
			clipboard.on('error', function(e) {
			    console.error('Action:', e.action);
			    console.error('Trigger:', e.trigger);
			});
		}
		
		(function copyCode(){
			if ($('.layout-post').length) {
			    preprocessing();
			    copy();
			} 
		})();
	</script>






<link rel="stylesheet" href="/plugin/fancybox/jquery.fancybox.css">


<script src="/plugin/fancybox/jquery.fancybox.js"></script>


<script type="text/javascript">
	(function gallerySet(){
		let titleID = $('.article-title a'),
			imageID = $('.article-content img'),
			videoID = $('.article-content video');
		
		let postTitle = titleID.text() ? titleID.text() : "No post title!";
		
		imageID.each(function() {
			let imgPath = $(this).attr('src'),
				imgTitle = $(this).attr('alt') ? $(this).attr('alt') : "No image description!";
		
			//给每个匹配的<img>元素打包, 即添加父元素<a>
			$(this).wrap('<a data-fancybox="gallery" data-caption="《 ' + postTitle + ' 》' + imgTitle + '"href="' + imgPath + '"> </a>');
		});
		
		videoID.each(function() {
			let videoPath = $(this).attr('src');
		
			//给每个匹配的<img>元素打包, 即添加父元素<a>
			$(this).wrap('<a data-fancybox href=" ' + videoPath + ' "> </a>');
		});
		
		//TODO：支持html5 video

		if($('#layout-post').length) {
			$('[data-fancybox="gallery"]').fancybox({
				loop: true,
				buttons: [
					"zoom",
					"share",
					"slideShow",
					"fullScreen",
					//"download",
					"thumbs",
					"close"
				],
				protect: true
			});
		}
	})();
</script>
		</main>

		<!--footer-->
		<footer>
	<div id="navigation-show">
		<ul id="global-nav">
	
		<li class="menu-home">
			<a href="/" class="menu-item-home" target="_blank">主页</a>
		</li>
		
	
		<li class="menu-archive">
			<a href="/archives" class="menu-item-archive" target="_blank">归档</a>
		</li>
		
	
		<li class="menu-categories">
			<a href="/categories" class="menu-item-categories" target="_blank">分类</a>
		</li>
		
	
		<li class="menu-tags">
			<a href="/tags" class="menu-item-tags" target="_blank">标签</a>
		</li>
		
	
		<li class="menu-about">
			<a href="/about" class="menu-item-about" target="_blank">关于</a>
		</li>
		
	

	
</ul>
	</div>

	<div class="copyright">
		<p>
			 
				&copy;2017 - 2020, content by Sariay. All Rights Reserved.
			
			
				<a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> Theme <a href="https://github.com/Sariay/hexo-theme-Annie" title="Annie" target="_blank" rel="noopener">Annie</a> by Sariay.
			
		</p>
		<p>
			

	<!-- busuanzi -->
	<!-- busuanzi -->



			<a href="javascript:zh_tran('s');" class="zh_click" id="zh_click_s">简体</a> 
			<a href="javascript:zh_tran('t');" class="zh_click" id="zh_click_t">繁體</a>				
		</p>
	</div>		
</footer>
		
	<!-- Local or hitokoto! -->

	
<script src="/plugin/motto/motto.js"></script>

	
	<script type="text/javascript">
		(function motto(){
			let mottoText = getMingYanContent().split('</br> - </br>'),
			
			mottoTextContent = mottoText[0]?mottoText[0]:'请刷新...',
			
			mottoTextFrom = mottoText[1]?mottoText[1]:'one/一个';
			
			mottoTextContent = mottoTextContent.trim().substring(0, 100);
		
			$("#motto-content").html( mottoTextContent);
			$("#motto-author").html( mottoTextFrom  );
		})();	
	</script>	



<!-- love effect -->


<!-- back to top -->

	<div id="totop">
	<span class="icon-circle-up"></span>
</div>



<!-- site analysis -->


	<!-- site-analysis -->
	
	
	
	
	
 

<!-- leancloud -->


	<!-- leancloud -->
	<!--
	时间：2018-11-27
	描述：
		文章访问量：visitors
		文章喜欢量：likes	
		文章排行榜：topNPost
		其他得说明：
			01-Cookie相关的函数 
				https://blog.csdn.net/somehow1002/article/details/78511541（Author：somehow1002）
			02-visitors相关的函数 
				https://blog.csdn.net/u013553529/article/details/63357382（Author：爱博客大伯）
				https://notes.doublemine.me/2015-10-21-为NexT主题添加文章阅读量统计功能.html（Author：夏末）
			03-topNPost相关的函数
				https://hoxis.github.io/hexo-next-read-rank.html（Author：hoxis）
			04-likes相关的函数，
				参考了01 & 02进行简单的设计与实现
-->


	

  



<script src="/plugin/chinese/chinese.js"></script>
<script src="/plugin/imagelazyloader/yall.min.js"></script>
<script src="/plugin/imageloaded/imagesloaded.pkgd.min.js"></script>
<script src="/plugin/nicescroll/jquery.nicescroll.js"></script>
<script src="/plugin/resizediv/resizediv.js"></script>
<script src="/js/main.js"></script>

	</body>	
</html>